{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMPL\n",
    "\n",
    "SMPL is a classical body model for human body shape and pose estimation. We can get joints position and the vertices of mesh from SMPL's results.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Download the SMPL's checkpoint and unzip it to `data_inputs/body_models/smpl`.\n",
    "\n",
    "```\n",
    ".\n",
    "├── SMPL_FEMALE.pkl\n",
    "├── SMPL_MALE.pkl\n",
    "└── SMPL_NEUTRAL.pkl\n",
    "```\n",
    "\n",
    "## References\n",
    "\n",
    "- [SMPL Project Page](https://smpl.is.tue.mpg.de/)\n",
    "- [SMPL-made-simple-FAQs](https://files.is.tue.mpg.de/black/talks/SMPL-made-simple-FAQs.pdf)\n",
    "\n",
    "## Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages you may use very often.\n",
    "import torch\n",
    "import numpy as np\n",
    "from smplx import SMPL\n",
    "from pytorch3d import transforms\n",
    "\n",
    "# Things you don't need to care about. They are just for driving the tutorials.\n",
    "from lib.utils.path_manager import PathManager\n",
    "from lib.viewer.wis3d_utils import HWis3D as Wis3D\n",
    "from lib.skeleton import Skeleton_SMPL24\n",
    "\n",
    "pm = PathManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SMPL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMPL has different models weights for different genders. Make sure you use the correct model for your project.\n",
    "\n",
    "Usually, we just use the neutral model if we can't access the gender information. \n",
    "\n",
    "Here, we will just use neutral model for simplicity. You can try the other genders if you want. You can just re-assign the `body_model` variable in the next cell and re-run the remaining cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n"
     ]
    }
   ],
   "source": [
    "body_models = {}\n",
    "genders = ['neutral', 'female', 'male']  # case insensitive\n",
    "\n",
    "for gender in genders:\n",
    "    body_models[gender] = SMPL(\n",
    "            model_path = pm.inputs / 'body_models' / 'smpl',\n",
    "            gender     = gender,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare some parameters for later inference.\n",
    "B = 150\n",
    "body_model : SMPL = body_models['neutral']  # use neutral for example\n",
    "\n",
    "# Prepare mesh template for later visualization.\n",
    "# Tips: mesh = vertices + faces, and the faces are the indices of vertices, which won't change across SMPL's outputs.\n",
    "mesh_temp : np.ndarray = body_model.faces  # (13776, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMPL Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 45, 3]) torch.Size([150, 6890, 3])\n"
     ]
    }
   ],
   "source": [
    "# Inference.\n",
    "smpl_out = body_model(\n",
    "        betas         = torch.zeros(B, 10),     # shape coefficients\n",
    "        global_orient = torch.zeros(B, 1, 3),   # axis-angle representation\n",
    "        body_pose     = torch.zeros(B, 23, 3),  # axis-angle representation\n",
    "        transl        = torch.zeros(B, 3),\n",
    "    )\n",
    "\n",
    "# Check output.\n",
    "joints : torch.Tensor = smpl_out.joints    # (B, 45, 3)\n",
    "verts  : torch.Tensor = smpl_out.vertices  # (B, 7890 3)\n",
    "print(joints.shape, verts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMPL Parameters\n",
    "\n",
    "Here we will learn the main for SMPL parameters through several demos. The main parameters are:\n",
    "\n",
    "1. betas\n",
    "2. global_orient\n",
    "3. body_pose\n",
    "4. transl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. betas | $\\beta \\in \\R^{||\\beta||}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betas control the shape of the model. Usually we use the default 10 shape coefficients. It depends on the model you load.\n",
    "\n",
    "You may see this(below) before, that means you are using a model with 10 shape coefficients.\n",
    "\n",
    "> \"WARNING: You are using a SMPL model, with only 10 shape coefficients.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_betas(\n",
    "    selected_component : int = 0,\n",
    "    lower_bound : int = -5,\n",
    "    upper_bound : int = +5,\n",
    "):\n",
    "    fake_betas = torch.zeros(B, 10)\n",
    "    fake_betas[:, selected_component] = torch.linspace(lower_bound, upper_bound, B)\n",
    "\n",
    "    # Inference.\n",
    "    smpl_out = body_model(\n",
    "            betas         = fake_betas,             # shape coefficients\n",
    "            global_orient = torch.zeros(B, 1, 3),   # axis-angle representation\n",
    "            body_pose     = torch.zeros(B, 23, 3),  # axis-angle representation\n",
    "            transl        = torch.zeros(B, 3),\n",
    "        )\n",
    "\n",
    "    # Check output.\n",
    "    joints : torch.Tensor = smpl_out.joints    # (B, 45 3)\n",
    "    verts  : torch.Tensor = smpl_out.vertices  # (B, 7890 3)\n",
    "\n",
    "    def visualize_results():\n",
    "        \"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\n",
    "        shape_wis3d = Wis3D(\n",
    "                pm.outputs / 'wis3d',\n",
    "                'SMPL-parameters',\n",
    "            )\n",
    "\n",
    "        shape_wis3d.add_motion_verts(\n",
    "                verts  = verts,\n",
    "                name   = f'shape: betas[:, {selected_component}] from {lower_bound} to {upper_bound}',\n",
    "                offset = 0,\n",
    "            )\n",
    "        shape_wis3d.add_motion_skel(\n",
    "                joints = joints[:, :24],\n",
    "                bones  = Skeleton_SMPL24.bones,\n",
    "                colors = Skeleton_SMPL24.bone_colors,\n",
    "                name   = f'shape: betas[:, {selected_component}] from {lower_bound} to {upper_bound}',\n",
    "                offset = 0,\n",
    "            )\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the effects of the changes on certain coefficient.\n",
    "\n",
    "Here, `learn_betas(k)` means we will visualize the SMPL outputs when the k-th coefficient is changed from -5 to +5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_betas(0)\n",
    "learn_betas(1)\n",
    "learn_betas(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the viewer.\n",
    "\n",
    "You will see that, the skeleton will mis-align with the mesh when the coefficients are very \"sharp\".\n",
    "Some of the coefficient control the height, the length of the limbs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the server. (Remember to terminate the cell before going on.)\n",
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. global_orient | $\\theta_r\\in\\R^3$ (part of $\\theta \\in \\R^{3\\times24}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global orient control the face direction of the virtual human, which is also the \"rotation\" of the root joint.\n",
    "\n",
    "You may have to check [axis angle](https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation) before going on.\n",
    "For example, a vector $\\vec{r} = [x, y, z]$ represents a rotation around the axis $\\frac{\\vec{r}}{||\\vec{r}||}$ in radians $||\\vec{r}||$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_orient():\n",
    "    fake_orient = torch.zeros(B, 1, 3)\n",
    "    fake_orient[   : 50, :, 0] = torch.linspace(0, 2 * np.pi, 50).reshape(50, 1)  # about x-axis\n",
    "    fake_orient[ 50:100, :, 1] = torch.linspace(0, 2 * np.pi, 50).reshape(50, 1)  # about y-axis\n",
    "    fake_orient[100:150, :, :] = torch.linspace(0, 2 * np.pi, 50).reshape(50, 1, 1).repeat(1, 1, 3)  # about x=y=z\n",
    "\n",
    "    # Inference.\n",
    "    smpl_out = body_model(\n",
    "            betas         = torch.zeros(B, 10),     # shape coefficients\n",
    "            global_orient = fake_orient,            # axis-angle representation\n",
    "            body_pose     = torch.zeros(B, 23, 3),  # axis-angle representation\n",
    "            transl        = torch.zeros(B, 3),\n",
    "        )\n",
    "\n",
    "    # Check output.\n",
    "    joints : torch.Tensor = smpl_out.joints    # (B, 45 3)\n",
    "    verts  : torch.Tensor = smpl_out.vertices  # (B, 7890 3)\n",
    "\n",
    "    def visualize_results():\n",
    "        \"\"\" This part is to visualize the results. You are supposed to ignore this part. \"\"\"\n",
    "        shape_wis3d = Wis3D(\n",
    "                pm.outputs / 'wis3d',\n",
    "                'SMPL-parameters',\n",
    "            )\n",
    "\n",
    "        # Prepare the rotation axis.\n",
    "        axis_x   = torch.tensor([[0, 0, 0], [3, 0, 0]], dtype=torch.float32)\n",
    "        axis_y   = torch.tensor([[0, 0, 0], [0, 3, 0]], dtype=torch.float32)\n",
    "        axis_xyz = torch.tensor([[0, 0, 0], [1, 1, 1]], dtype=torch.float32)\n",
    "        axis_all = torch.concat(\n",
    "            [\n",
    "                axis_x.reshape(1, 2, 3).repeat(50, 1, 1),\n",
    "                axis_y.reshape(1, 2, 3).repeat(50, 1, 1),\n",
    "                axis_xyz.reshape(1, 2, 3).repeat(50, 1, 1),\n",
    "            ],\n",
    "            dim = 0,\n",
    "        )\n",
    "        axis_all[:, :, :] += joints[:, [0], :] # move the axis to the root joints\n",
    "\n",
    "\n",
    "        shape_wis3d.add_vec_seq(\n",
    "            vecs = axis_all,\n",
    "            name = 'orient: rotation axis',\n",
    "        )\n",
    "        shape_wis3d.add_motion_verts(\n",
    "                verts  = verts,\n",
    "                name   = f'orient: vertices',\n",
    "                offset = 0,\n",
    "            )\n",
    "        shape_wis3d.add_motion_skel(\n",
    "                joints = joints[:, :24],\n",
    "                bones  = Skeleton_SMPL24.bones,\n",
    "                colors = Skeleton_SMPL24.bone_colors,\n",
    "                name   = f'orient: skeleton',\n",
    "                offset = 0,\n",
    "            )\n",
    "    visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the effects of the changes on `global_orient`.\n",
    "\n",
    "Here, `learn_orient()` will rotate the digital human in three ways:\n",
    "\n",
    "1. `fake_orient[  0: 50]` = $[0, 0, 0] \\rightarrow [2\\pi,  0, 0 ]$, rotation about $x$-axis\n",
    "2. `fake_orient[ 50:100]` = $[0, 0, 0] \\rightarrow [ 0, 2π, 0 ]$, rotation about $y$-axis\n",
    "3. `fake_orient[100:150]` = $[0, 0, 0] \\rightarrow [2π, 2π, 2π]$, rotation about $x=y=z$ axis\n",
    "\n",
    "You are supposed to make sure you understand the axis-angle representation before going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_orient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the Wis3D viewer.\n",
    "\n",
    "You will see that, the rotation axis starts from the position of root joint, rather than the origin of the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still one thing you should know: the exact value of global orientation is related to the **coordinates** (e.g., camera coordinates, global coordinates) you are using. (So is the translation in SMPL.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. body_pose | $\\theta_b\\in\\R^{3\\times23}$ (part of $\\theta \\in \\R^{3\\times24}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. transl | $\\Gamma\\in\\R^{3}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
