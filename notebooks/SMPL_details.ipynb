{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMPL-details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages you may use very often.\n",
    "import torch\n",
    "import numpy as np\n",
    "from smplx import SMPL\n",
    "from smplx.vertex_ids import vertex_ids as VERTEX_IDS\n",
    "from pytorch3d import transforms  # You may use this package when performing rotation representation transformation.\n",
    "\n",
    "# Things you don't need to care about. They are just for driving the tutorials.\n",
    "from lib.logger.look_tool import look_tensor\n",
    "from lib.utils.path_manager import PathManager\n",
    "from lib.viewer.wis3d_utils import HWis3D as Wis3D\n",
    "from lib.skeleton import Skeleton_SMPL24\n",
    "\n",
    "pm = PathManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n"
     ]
    }
   ],
   "source": [
    "body_model_smpl = SMPL(\n",
    "        model_path = pm.inputs / 'body_models' / 'smpl',\n",
    "        gender     = 'neutral',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Joint Regressor\n",
    "\n",
    "You can get J_regressor from `smplx.SMPL(...).J_regressor`. It's used to regress the joints from the vertices. To be specific, it's a matrix of size `(24, 6890)`, and the joint positions can be got from the linear combination of the relative vertices positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 6890])\n",
      "v shape = torch.Size([1, 6890, 3]), j shape = torch.Size([1, 24, 3])\n",
      "j_by_hand shape = torch.Size([1, 24, 3])\n",
      "shape = (1, 24, 3)\tdtype = torch.float32\tdevice = cpu\tmin/max/mean/std = [ -0.000000 -> 0.000000 ] ~ ( 0.000000, 0.000000 )\n"
     ]
    }
   ],
   "source": [
    "J_regressor = body_model_smpl.J_regressor  # (24, 6890)\n",
    "print(J_regressor.shape)\n",
    "\n",
    "# Get 'g.t.' of the SMPL's output.\n",
    "smpl_output = body_model_smpl()\n",
    "v = smpl_output.vertices.detach()\n",
    "j = smpl_output.joints[:, :24, :].detach()\n",
    "print(f'v shape = {v.shape}, j shape = {j.shape}')\n",
    "\n",
    "# Calculate the joints through J_regressor.\n",
    "j_by_hand = torch.matmul(J_regressor[None], v)\n",
    "print(f'j_by_hand shape = {j_by_hand.shape}')\n",
    "\n",
    "# Check the difference.\n",
    "delta = j - j_by_hand\n",
    "_ = look_tensor(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, they have tiny difference (for the first 24 joints). But if you can get joints from the standard output object, you are still suggested to get the joints from that.  \n",
    "\n",
    "> Sometimes, we want the SMPL style 24 joints, but we only have the SMPL-X style parameters. As we have already shown, you can't use SMPL-X parameters to get SMPL's output directly. But you can first use a regressor to get the SMPL style 6890 vertices from SMPL-X style 10475 vertices, and then use the `J_regressor` to get the SMPL style 24 joints from the regressed 6890 vertices. We won't talk about these details here, but you can keep this in mind.\n",
    "\n",
    "Another thing you may need to know is that, the regressor is sparse, which means that most of the elements are zeros. Now let's get into the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the total 165360, there are 165124 zeros, zero rate: 0.998573%.\n"
     ]
    }
   ],
   "source": [
    "# Statistics of the J_regressor.\n",
    "zero_cnt = (J_regressor == 0).sum().item()\n",
    "total_cnt = J_regressor.numel()\n",
    "print(f'Among the total {total_cnt}, there are {zero_cnt} zeros, zero rate: {zero_cnt / total_cnt:.6f}%.')\n",
    "\n",
    "# Visualize the joints.\n",
    "active_masks = (J_regressor != 0)  # (24, 6890)\n",
    "J_regressor_wis3d = Wis3D(\n",
    "        pm.outputs / 'wis3d',\n",
    "        'SMPL-J_regressor',\n",
    "    )\n",
    "# Add first reference skeleton and mesh.\n",
    "J_regressor_wis3d.add_motion_verts(verts=v.repeat(25, 1, 1), name=f'vertices', offset=0)\n",
    "J_regressor_wis3d.add_motion_skel(joints=j.repeat(25, 1, 1), bones=Skeleton_SMPL24.bones, colors=Skeleton_SMPL24.bone_colors, name=f'skeleton', offset=0)\n",
    "\n",
    "# Visualize each part of the J_regressor.\n",
    "for i in range(24):\n",
    "    mask = active_masks[i]\n",
    "    v_masked = v[0, mask]\n",
    "    # Visualize the things of interest.\n",
    "    J_regressor_wis3d.set_scene_id(i+1)\n",
    "    J_regressor_wis3d.add_point_cloud(vertices=v_masked, name=f'VOI-{i}')  # Vertices of interest used to regress i-th joint.\n",
    "    J_regressor_wis3d.add_spheres(centers=v_masked, radius=0.01, name=f'VOI-{i}')  # VOI used to regress i-th joint.\n",
    "    J_regressor_wis3d.add_spheres(centers=j[:1, i], radius=0.02, name=f'joint-{i}')  # i-th joint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize the active elements of the regressor to show exactly which vertices influence the joints regressed. You are supposed to interact with the Wis3D UI to check the things you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the server. (Remember to terminate the cell before going on.)\n",
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the Joints 45\n",
    "\n",
    "You may notice that, when I mention \"joints\", I always refer to the first 24. But there are actually 45 joints returned by the SMPL model by default. So what are they?\n",
    "\n",
    "Actually, the 45 joints can be divided into two parts:\n",
    "\n",
    "1. The common SMPL joints, which are first regressed from shapped vertices, and then transformed by the pose parameters. They are the first 24 joints.\n",
    "2. Joints selected (by hand, in advance) from vertices. There are 21 of them by default. You can get the name and the vertices index of them from `smplx.vertex_ids.vertex_ids['smplh']`, I print them below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected joints from vertices.\n",
      "---------------------------------\n",
      "|  joint_name \t|\tvid\t|\n",
      "---------------------------------\n",
      "|  nose  \t|\t332\t|\n",
      "|  reye  \t|\t6260\t|\n",
      "|  leye  \t|\t2800\t|\n",
      "|  rear  \t|\t4071\t|\n",
      "|  lear  \t|\t583\t|\n",
      "|  rthumb  \t|\t6191\t|\n",
      "|  rindex  \t|\t5782\t|\n",
      "|  rmiddle  \t|\t5905\t|\n",
      "|  rring  \t|\t6016\t|\n",
      "|  rpinky  \t|\t6133\t|\n",
      "|  lthumb  \t|\t2746\t|\n",
      "|  lindex  \t|\t2319\t|\n",
      "|  lmiddle  \t|\t2445\t|\n",
      "|  lring  \t|\t2556\t|\n",
      "|  lpinky  \t|\t2673\t|\n",
      "|  LBigToe  \t|\t3216\t|\n",
      "|  LSmallToe  \t|\t3226\t|\n",
      "|  LHeel  \t|\t3387\t|\n",
      "|  RBigToe  \t|\t6617\t|\n",
      "|  RSmallToe  \t|\t6624\t|\n",
      "|  RHeel  \t|\t6787\t|\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Selected joints from vertices.')\n",
    "print(f'---------------------------------')\n",
    "print(f'|  joint_name \\t|\\tvid\\t|')\n",
    "print(f'---------------------------------')\n",
    "for k, v in VERTEX_IDS['smplh'].items():\n",
    "    print(f'|  {k}  \\t|\\t{v}\\t|')\n",
    "print(f'---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the implementation at `smplx.SMPL` for more details, SMPL provide some APIs to customize the outputs. They will be useful if you need to change the definition of the output joints (in order, or maybe select more joints from vertices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Become Lighter\n",
    "\n",
    "The sparsity of the regressor tells that, if we only need the joint positions, we don't have to get all the vertices. Recall the inference process of SMPL, we found that we can ignore a lot of calculation while performing the Linear Blend Skinning, LBS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Blending Skinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eg_params(eg_path):\n",
    "    eg_params = np.load(eg_path, allow_pickle=True).item()\n",
    "    betas = torch.from_numpy(eg_params['betas']).squeeze(0)  # (10,)\n",
    "    poses = torch.cat([\n",
    "            torch.from_numpy(eg_params['global_orient']).squeeze(0),  # (1, 3)\n",
    "            torch.from_numpy(eg_params['body_pose']).squeeze(0),  # (23, 3)\n",
    "        ], dim=0)  # (24, 3)\n",
    "    poses[0, :] = 0  # clear the global rotation for easy visualization\n",
    "    poses = transforms.axis_angle_to_matrix(poses)  # (24, 3, 3)\n",
    "    return betas, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example data.\n",
    "betas, poses = load_eg_params(pm.inputs / 'examples/ballerina.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce the LBS\n",
    "\n",
    "For easier testing on different cases, you can simply change the loaded data and just rerun this sections (4 blocks in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the necessary data matrices from the body model for reproducing.\n",
    "# These things are gender-specific and are contained in the SMPL model files.\n",
    "v_template  = body_model_smpl.v_template   # (6890, 3)\n",
    "shape_disp  = body_model_smpl.shapedirs    # (6890, 3, 10)\n",
    "poses_disp  = body_model_smpl.posedirs     # (207=23*9, 20670=6890*3)\n",
    "lbs_weights = body_model_smpl.lbs_weights  # (6890, 24)\n",
    "parents     = body_model_smpl.parents      # (24,), indicating the kinematic stuctures\n",
    "J_regressor = body_model_smpl.J_regressor  # (24, 6890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce smplx.lbs.lbs().\n",
    "\n",
    "# \\bar{T}, the template in the rest pose.\n",
    "v_temp = v_template.clone()  # (6890, 3)\n",
    "\n",
    "# B_S, the shape-specific template deformation.\n",
    "Bs = torch.einsum('l,mkl->mk', betas, shape_disp).clone()  # (6890, 3)\n",
    "v_temp_Bs = v_temp + Bs  # (6890, 3)\n",
    "\n",
    "# B_P, the pose-dependent template deformation.\n",
    "ident = torch.eye(3)  # (3, 3), indicates 'offsets'\n",
    "poses_feat = (poses[1:] - ident[None]).reshape(-1)  # (207=23*9,) root orientation not included.\n",
    "Bp = torch.einsum('l,lk->k', poses_feat, poses_disp).reshape(6890, 3).clone()  # (6890, 3)\n",
    "v_temp_Bs_Bp = v_temp_Bs + Bp  # (6890, 3)\n",
    "v_temp_Bp = v_temp + Bp  # (6890, 3), for checking\n",
    "\n",
    "# B_{pose}, we should perfom a FK to get the global transformations for each joint.\n",
    "from smplx.lbs import batch_rigid_transform, vertices2joints\n",
    "\n",
    "def rig_v_temp(v):\n",
    "    J_temp = vertices2joints(J_regressor, v[None])  # (1, 24, 3), the transformations is performed based on the skeleton\n",
    "    J_final, joint_global_orents = batch_rigid_transform(poses, J_temp, parents)  # FK the local rotations to global ones\n",
    "    A = joint_global_orents.squeeze(0)  # (24, 4, 4)\n",
    "    W = lbs_weights  # (6890, 24)\n",
    "    T = torch.einsum('vj,jxy->vxy', W, A)  # (6890, 4, 4), remove the rest pose\n",
    "    homogen_coord = torch.ones([6890, 1])  # (6890, 1)\n",
    "    v_posed_homo = torch.cat([v, homogen_coord], dim=1)  # (6890, 4)\n",
    "    v_homo = torch.einsum('vij,vj->vi', T, v_posed_homo)  # (6890, 4)\n",
    "    return {\n",
    "        'j_temp' : J_temp.squeeze(),\n",
    "        'j'      : J_final.squeeze(),\n",
    "        'v'      : v_homo[:, :3]\n",
    "    }\n",
    "\n",
    "final_on_temp_Bs_Bp = rig_v_temp(v_temp_Bs_Bp)\n",
    "final_on_temp_Bs    = rig_v_temp(v_temp_Bs)\n",
    "final_on_temp       = rig_v_temp(v_temp)\n",
    "final_on_temp_Bp    = rig_v_temp(v_temp_Bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 3])\n"
     ]
    }
   ],
   "source": [
    "# Visualize.\n",
    "LBS_wis3d = Wis3D(\n",
    "        pm.outputs / 'wis3d',\n",
    "        'SMPL-LBS',\n",
    "    )\n",
    "faces = body_model_smpl.faces\n",
    "\n",
    "LBS_wis3d.set_scene_id(0)\n",
    "LBS_wis3d.add_mesh(vertices = v_temp, faces = faces, name = 'v_template')\n",
    "LBS_wis3d.add_motion_skel(\n",
    "    joints = final_on_temp['j_temp'][None],\n",
    "    bones  = Skeleton_SMPL24.bones,\n",
    "    colors = Skeleton_SMPL24.bone_colors,\n",
    "    name   = 'j_temp at mean pose',\n",
    "    offset = 0,\n",
    ")\n",
    "\n",
    "LBS_wis3d.set_scene_id(1)\n",
    "LBS_wis3d.add_mesh(vertices = v_temp_Bs, faces = faces, name = 'v_shaped')\n",
    "LBS_wis3d.add_motion_skel(\n",
    "    joints = final_on_temp_Bs['j_temp'][None],\n",
    "    bones  = Skeleton_SMPL24.bones,\n",
    "    colors = Skeleton_SMPL24.bone_colors,\n",
    "    name   = 'j_temp after shape deformation',\n",
    "    offset = 1,\n",
    ")\n",
    "\n",
    "LBS_wis3d.set_scene_id(2)\n",
    "LBS_wis3d.add_mesh(vertices = v_temp_Bs_Bp, faces = faces, name = 'v_posed')\n",
    "LBS_wis3d.add_motion_skel(\n",
    "    joints = final_on_temp_Bs_Bp['j_temp'][None],\n",
    "    bones  = Skeleton_SMPL24.bones,\n",
    "    colors = Skeleton_SMPL24.bone_colors,\n",
    "    name   = 'j_temp after shape deformation and pose-dependent deformation',\n",
    "    offset = 2,\n",
    ")\n",
    "\n",
    "LBS_wis3d.set_scene_id(3)\n",
    "LBS_wis3d.add_mesh(vertices=final_on_temp_Bs_Bp['v'], faces=faces, name='v_final')\n",
    "LBS_wis3d.add_mesh(vertices=final_on_temp_Bs['v'],    faces=faces, name='v_final without B_P')\n",
    "LBS_wis3d.add_mesh(vertices=final_on_temp_Bp['v'],    faces=faces, name='v_final without B_S')\n",
    "LBS_wis3d.add_mesh(vertices=final_on_temp['v'],       faces=faces, name='v_final without B_P and B_S')\n",
    "LBS_wis3d.add_motion_skel(\n",
    "    joints = final_on_temp_Bs_Bp['j'][None],\n",
    "    bones  = Skeleton_SMPL24.bones,\n",
    "    colors = Skeleton_SMPL24.bone_colors,\n",
    "    name   = 'j_final',\n",
    "    offset = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the server. (Remember to terminate the cell before going on.)\n",
    "!wis3d --vis_dir {pm.outputs / 'wis3d'} --host 0.0.0.0 --port 19090"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
